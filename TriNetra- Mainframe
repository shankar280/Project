import speech_recognition as sr
import pyttsx3
import datetime


listener = sr.Recognizer()
trinetra = pyttsx3.init()
voices = trinetra.getProperty('voices')
trinetra.setProperty('voice', voices[73].id)
trinetra.setProperty('rate',160)


def talk(text):
    trinetra.say(text)
    trinetra.runAndWait()


def take_command():
    command= ""
    try:
        with sr.Microphone() as source:
            print('listening...')
            voice = listener.listen(source)
        command = listener.recognize_google(voice)
        command = command.lower()
        print(command)
            
    except:
        print("No command detected!")
        pass
    return command

def num():
    i = 0
    while True:
        i = i+1 
        print(i)
        talk(i)
        command = take_command()
        if 'trinetra' in command:
            command = command.replace('trinetra', '')
            if 'stop' in command:
                talk("stoppingggg") 
                break;





#Img to text
def imgtotext():
    import pytesseract
    import cv2
    from PIL import Image
    import os
    import pyttsx3

    language = 'en'
    engine = pyttsx3.init()
    engine.setProperty('rate', 100) 
    key = cv2. waitKey(1)
    webcam = cv2.VideoCapture(0)
    while True:
        try:
            check, frame = webcam.read()
            cv2.imshow("Capturing", frame)
            key = cv2.waitKey(1)
            if key == ord('z'):
                engine.say("Image captured")
                cv2.imwrite(filename='/home/user/P3i/saved_img.jpg', img=frame)
                webcam.release()
                string = pytesseract.image_to_string('/home/user/P3i/saved_img.jpg')
                engine.say("Here's your content: ")
                print(string)
                engine.setProperty('rate', 160)
                engine.say(string)
                engine.runAndWait()
                print("Image saved!")
                cv2.destroyAllWindows()
                break
                
            
        except(KeyboardInterrupt):
            print("Turning off camera.")
            webcam.release() 
            print("Camera off.")
            print("Program ended.")
            cv2.destroyAllWindows()
            break
            
            
            
#Img to text end



#Object list
        
def objlist():
    import cv2
    import time

    #thres = 0.30 # Threshold to detect object

    classNames = []
    classFile = "/home/user/Downloads/obj detection/Object_Detection_Files/coco.names"
    with open(classFile,"rt") as f:
        classNames = f.read().rstrip("\n").split("\n")

    configPath = "/home/user/Downloads/obj detection/Object_Detection_Files/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt"
    weightsPath = "/home/user/Downloads/obj detection/Object_Detection_Files/frozen_inference_graph.pb"

    net = cv2.dnn_DetectionModel(weightsPath,configPath)
    net.setInputSize(320,320)
    net.setInputScale(1.0/ 127.5)
    net.setInputMean((127.5, 127.5, 127.5))
    net.setInputSwapRB(True)

    objlist = []
    def getObjects(img, thres, nms, draw=True, objects=[]):
        classIds, confs, bbox = net.detect(img,confThreshold=thres,nmsThreshold=nms)
        #print(classIds,bbox)
        if len(objects) == 0: objects = classNames
        objectInfo =[]
        if len(classIds) != 0:
            for classId, confidence,box in zip(classIds.flatten(),confs.flatten(),bbox):
                className = classNames[classId - 1]
                if className in objects:
                    objectInfo.append(className)
                    if (draw):
                        cv2.rectangle(img,box,color=(0,255,0),thickness=2)
                        cv2.putText(img,classNames[classId-1].upper(),(box[0]+10,box[1]+30),
                        cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)

                        objlist.append(classNames[classId-1])



                        cv2.putText(img,str(round(confidence*100,2)),(box[0]+200,box[1]+30),
                        cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)

        return img,objectInfo




    cap = cv2.VideoCapture(0)
    cap.set(3,640)
    cap.set(4,480)
    #cap.set(10,70)

    timeout = time.time() + 8
    while time.time() < timeout:
             
        success, img = cap.read()
        result, objectInfo = getObjects(img,0.45,0.2)
            
        cv2.imshow("Output",img)

        k = cv2.waitKey(1) & 0xFF 
            # press 'q' to exit
        if k == ord('q'):
            break
    objlist = list(set(objlist))  
    print(objlist)
    talk('objects are')
    talk(objlist)        
        
        
#Object list end


# Search Object
            
def searchobj():
    import cv2
    talk("which thing you want to search?")
    obj = take_command()
    print(obj)
    talk(obj + "searchinggggg")
    thres = 0.30 # Threshold to detect object

    classNames = []
    classFile = "/home/user/Downloads/obj detection/Object_Detection_Files/coco.names"
    with open(classFile,"rt") as f:
        classNames = f.read().rstrip("\n").split("\n")

    configPath = "/home/user/Downloads/obj detection/Object_Detection_Files/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt"
    weightsPath = "/home/user/Downloads/obj detection/Object_Detection_Files/frozen_inference_graph.pb"


    net = cv2.dnn_DetectionModel(weightsPath,configPath)
    net.setInputSize(320,320)
    net.setInputScale(1.0/ 127.5)
    net.setInputMean((127.5, 127.5, 127.5))
    net.setInputSwapRB(True)


    def getObjects(img, thres, nms, draw=True, objects=[]):
        classIds, confs, bbox = net.detect(img,confThreshold=thres,nmsThreshold=nms)
        #print(classIds,bbox)
        if len(objects) == 0: objects = classNames
        objectInfo =[]
        if len(classIds) != 0:
            for classId, confidence,box in zip(classIds.flatten(),confs.flatten(),bbox):
                className = classNames[classId - 1]
                if className in objects:
                    objectInfo.append([box,className])
                    if (draw):
                        cv2.rectangle(img,box,color=(0,255,0),thickness=2)
                        cv2.putText(img,classNames[classId-1].upper(),(box[0]+10,box[1]+30),
                        cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)
                        cv2.putText(img,str(round(confidence*100,2)),(box[0]+200,box[1]+30),
                        cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)

        return img,objectInfo




    cap = cv2.VideoCapture(0)
    cap.set(3,640)
    cap.set(4,480)
    #cap.set(10,70)


    while True:
        objectInfo = []
        success, img = cap.read()
        result, objectInfo = getObjects(img,0.45,0.2, objects=[obj])
        print(objectInfo)
        if len(objectInfo) != 0:
            talk ( obj + "found")
            break

        else: pass
        cv2.imshow("Output",img)
        
        k = cv2.waitKey(1) & 0xFF 
        # press 'q' to exit
        if k == ord('q'):
            break
    
            
# Search Object end






#Face Detection
import tkinter as tk
from tkinter import ttk
from tkinter import messagebox as mess
import tkinter.simpledialog as tsd
import cv2,os
import csv
import numpy as np
from PIL import Image
import pandas as pd
import datetime
import time
def assure_path_exists(path):
    dir = os.path.dirname(path)
    if not os.path.exists(dir):
        os.makedirs(dir)

def check_haarcascadefile():
    exists = os.path.isfile("/home/user/Downloads/facedetect/haarcascade_frontalface_default.xml")
    if exists:
        pass
    else:
        mess._show(title='Some file missing', message='Please contact us for help')
        window.destroy()

def TakeImages():
    check_haarcascadefile()
    columns = ['SERIAL NO.', '', 'ID', '', 'NAME']
    assure_path_exists("/home/user/Downloads/facedetect/StudentDetails/")
    assure_path_exists("/home/user/Downloads/facedetect/TrainingImage/")
    serial = 0
    exists = os.path.isfile("/home/user/Downloads/facedetect/StudentDetails/StudentDetails.csv")
    if exists:
        with open("/home/user/Downloads/facedetect/StudentDetails/StudentDetails.csv", 'r') as csvFile1:
            reader1 = csv.reader(csvFile1)
            for l in reader1:
                serial = serial + 1
        serial = (serial // 2)
        csvFile1.close()
    else:
        with open("/home/user/Downloads/facedetect/StudentDetails/StudentDetails.csv", 'a+') as csvFile1:
            writer = csv.writer(csvFile1)
            writer.writerow(columns)
            serial = 1
        csvFile1.close()
    Id = input("Enter ID")
    name = input("Enter Name")
    if ((name.isalpha()) or (' ' in name)):
        cam = cv2.VideoCapture(0)
        harcascadePath = "/home/user/Downloads/facedetect/haarcascade_frontalface_default.xml"
        detector = cv2.CascadeClassifier(harcascadePath)
        sampleNum = 0
        while (True):
            ret, img = cam.read()
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            faces = detector.detectMultiScale(gray, 1.3, 5)
            for (x, y, w, h) in faces:
                cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)
                # incrementing sample number
                sampleNum = sampleNum + 1
                # saving the captured face in the dataset folder TrainingImage
                cv2.imwrite("/home/user/Downloads/facedetect/TrainingImage/" + name + "." + str(serial) + "." + Id + '.' + str(sampleNum) + ".jpg",
                            gray[y:y + h, x:x + w])
                # display the frame
                cv2.imshow('Taking Images', img)
            # wait for 100 miliseconds
            if cv2.waitKey(100) & 0xFF == ord('q'):
                break
            # break if the sample number is morethan 100
            elif sampleNum > 100:
                break
        cam.release()
        cv2.destroyAllWindows()
        res = "Images Taken for ID : " + Id
        row = [serial, '', Id, '', name]
        with open('/home/user/Downloads/facedetect/StudentDetails/StudentDetails.csv', 'a+') as csvFile:
            writer = csv.writer(csvFile)
            writer.writerow(row)
        csvFile.close()
        
    else:
        if (name.isalpha() == False):
            res = "Enter Correct name"
    

def getImagesAndLabels(path):
    # get the path of all the files in the folder
    imagePaths = [os.path.join(path, f) for f in os.listdir(path)]
    # create empth face list
    faces = []
    # create empty ID list
    Ids = []
    # now looping through all the image paths and loading the Ids and the images
    for imagePath in imagePaths:
        # loading the image and converting it to gray scale
        pilImage = Image.open(imagePath).convert('L')
        # Now we are converting the PIL image into numpy array
        imageNp = np.array(pilImage, 'uint8')
        # getting the Id from the image
        ID = int(os.path.split(imagePath)[-1].split(".")[1])
        # extract the face from the training image sample
        faces.append(imageNp)
        Ids.append(ID)
    return faces, Ids


def TrainImages():
    check_haarcascadefile()
    assure_path_exists("/Users/gourishankar/Downloads/me/TrainingImageLabel/")
    recognizer = cv2.face_LBPHFaceRecognizer.create()
    harcascadePath = "/home/user/Downloads/facedetect/haarcascade_frontalface_default.xml"
    detector = cv2.CascadeClassifier(harcascadePath)
    pt ="/home/user/Downloads/facedetect/TrainingImage/"
    faces, ID = getImagesAndLabels(pt)
    

   
    try:
        recognizer.train(faces, np.array(ID))
    except:
        mess._show(title='No Registrations', message='Please Register someone first!!!')
        return
    recognizer.save("/home/user/Downloads/facedetect/TrainingImageLabel/Trainner.yml")
    res = "Profile Saved Successfully"
    print('Total Registrations till now  : ' + str(ID[0]))



def TrackImages():
    check_haarcascadefile()
    assure_path_exists("/home/user/Downloads/facedetect/StudentDetails")
    
    msg = ''
    i = 0
    j = 0
    recognizer = cv2.face.LBPHFaceRecognizer_create()  # cv2.createLBPHFaceRecognizer()
    exists3 = os.path.isfile("/home/user/Downloads/facedetect/TrainingImageLabel/Trainner.yml")
    if exists3:
        recognizer.read("/home/user/Downloads/facedetect/TrainingImageLabel/Trainner.yml")
    else:
        mess._show(title='Data Missing', message='Please click on Save Profile to reset data!!')
        return
    harcascadePath = "/home/user/Downloads/facedetect/haarcascade_frontalface_default.xml"
    faceCascade = cv2.CascadeClassifier(harcascadePath);

    cam = cv2.VideoCapture(0)
    font = cv2.FONT_HERSHEY_SIMPLEX
    col_names = ['Id', '', 'Name', '', 'Date', '', 'Time']
    exists1 = os.path.isfile("/home/user/Downloads/facedetect/StudentDetails/StudentDetails.csv")
    if exists1:
        df = pd.read_csv("/home/user/Downloads/facedetect/StudentDetails/StudentDetails.csv")
    else:
        mess._show(title='Details Missing', message='Students details are missing, please check!')
        cam.release()
        cv2.destroyAllWindows()
        window.destroy()
    
    count = 0
    count2 = 0
    plist = []
    while True:
        ret, im = cam.read()
        gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
        faces = faceCascade.detectMultiScale(gray, 1.2, 5)
        for (x, y, w, h) in faces:
            cv2.rectangle(im, (x, y), (x + w, y + h), (225, 0, 0), 2)
            serial, conf = recognizer.predict(gray[y:y + h, x:x + w])
            if (conf < 50):
                ts = time.time()
                date = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y')
                timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
                aa = df.loc[df['SERIAL NO.'] == serial]['NAME'].values
                ID = df.loc[df['SERIAL NO.'] == serial]['ID'].values
                ID = str(ID)
                ID = ID[1:-1]
                bb = str(aa)
                bb = bb[2:-2]
                attendance = [str(ID), '', bb, '', str(date), '', str(timeStamp)]
                
                if str(bb) not in plist:
                    if count == 0:
                        talk('Person recognized!')
                        talk('The person is')
                        talk(str(bb))
                        plist.append(str(bb))
                        count = 1
                    else:
                        talk('Another Person recognized!')
                        talk('The person is')
                        talk(str(bb))
                        plist.append(str(bb))

            else:
                Id = 'Unknown'
                bb = str(Id)
                if count2 == 0:
                    talk('Unknown Person detected!')
                    count2 = 1
                    
            cv2.putText(im, str(bb), (x, y + h), font, 1, (255, 255, 255), 2)
        cv2.imshow('Taking Attendance', im)
        if (cv2.waitKey(1) == ord('q')):
            break
    
    cam.release()
    cv2.destroyAllWindows()
#Face detection end


def run_trinetra():
    
    command = take_command()
    if 'trinetra' in command:
        command = command.replace('trinetra', '')
        
        if 'time' in command:
            time = datetime.datetime.now().strftime('%I:%M %p')
            print(time)
            talk(time)
             
      
        elif 'take image' in command:
            TrackImages()
            
        elif 'search object' in command:
            searchobj()
            
        elif 'read' in command:    
            imgtotext()
        
        elif 'object list' in command:    
            objlist()
            
            
        else:
            print("Not understandable")
            talk("Sorry boss, command is not understandable")
        


while True:
    run_trinetra()
